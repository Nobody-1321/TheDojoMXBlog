---
title: "Reseña del libro 'Deep Learning' de MIT Press Essential Knowledge Series"
date: 2025-02-23
author: Héctor Patricio
tags: libros deep-learning machine-learning matemáticas
comments: true
excerpt: "Hablemos del libro 'Deep Learning' de MIT Essential Knowledge Series, una introducción suficiente al tema."
header:
  overlay_image: https://res.cloudinary.com/hectorip/image/upload/c_scale,w_1440/v1740316729/daniele-levis-pelusi-1UT5e8z0x-s-unsplash_o9pag2.jpg
  teaser: https://res.cloudinary.com/hectorip/image/upload/c_scale,w_440/v1740316729/daniele-levis-pelusi-1UT5e8z0x-s-unsplash_o9pag2.jpg
  overlay_filter: rgba(0, 0, 0, 0.5)
---

La serie **The MIT Press Essential Knowledge Series** es una serie de libros de introducción
a diferentes temas interesantes y actuales, sobre todo de ciencia y tecnología.

Me gustan mucho porque son lo suficientemente introductorios para que cualquiera
sin conocimiento previo del tema específico pueda introducirse, pero lo suficientemente
completos para salir con una buena visión general de ese tema específico.

El libro del que quiero hablar es de un tema que se ha vuelto cada vez más importante,
el **Deep Learning**.

## Reseña del Deep Learning de John D. Kelleher

![Portada del libro Deep Learning de John D. Kelleher](https://res.cloudinary.com/hectorip/image/upload/v1740318616/Deep_learning_csd5gy.jpg){: .align-center}

En este libro empezarás desde la introducción a lo que llamamos inteligencia artificial,
machine learning y finalmente deep learning, junto con los efectos que ha tenido en el mundo.

Me gusta mucho que el libro te explica en términos simples la base matemática que sustenta
todo lo que hacemos con los modelos y te aclara los términos que se escuchan por todos lados
sin ser tan difícil de entender. Por ejemplo:

- Te aclara que un **modelo** es una función en el sentido matemático y te explica cuál es el
trabajo del entrenamiento para llegar a ese modelo
- Explica lo que es el **aprendizaje** y la **experiencia**
- Aclara qué es un **parámetro**
- Deja muy claros los pasos de **entrenamiento** e **inferencia**

Después de poner las cartas sobre la mesa respecto términos y definiciones, se pasa a hablar
de la historia de la inteligencia artificial y cómo es que llegamos _casi_ hasta donde estamos
ahora, porque este libro se escribió antes del boom de los LLMs, pero viéndolo desde nuestra
perspectiva te puedes dar cuenta de lo mucho que sabe el autor del tema porque ya menciona
a los transformadores (la base de los LLMs modernos) como un tipo de modelo de Deep Learning importante.

Después de esto, pasa a explicar cómo se entrena a un perceptrón, o un modelo de una neurona,
para que puedas entender el procedimiento básico y después pasar a los modelos que son
el centro del libro: los modelos profundos.

En este libro aprenderás que el deep learning es simplemente una forma de entrenar modelos
que están compuestos por varias capas de neuronas, y que es un campo en sí mismo porque
estos modelos no son tan fáciles de entrenar e incluso requieren matemáticas específicas y
técnicas que han ido surgiendo con la prueba y el error.

El libro te explica dos algoritmos esenciales en el deep learning:

- El descenso de gradiente (gradient descent)
- El algoritmo de retropropagación (backpropagation)

Esta es la parte más pesada del libro respecto a matemáticas, incluso dice que te la puedes
leer por encima si te cuestan mucho trabajo, pero que también puedes comprobar por ti
mismo las matemáticas que te explica. Aquí es justo donde digo que esta serie profundiza
lo suficiente para no sentirse como un libro sin profundidad que es la pura introducción.

El libro finaliza con un análisis de lo que el autor considera lo que sigue para el deep learning
y la inteligencia artificial en general, como la explicabilidad, la eficiencia, el cómputo
especializado en imitar el cerebro, los transformadores (BERT), etc.

Espero que este resumen te de una idea de lo que trata el libro.

## Conclusión y opinión

Si te quieres entender de manera un poco más profunda cómo funcionan las redes
neuronales en general y los detalles de las redes neuronales profundas, este
libro es una excelente introducción, porque incluso te da un viaje por las matemáticas
detrás del entrenamiento de los modelos que usamos diariamente.

Como se escribió en 2019, no te habla de LLMs o cosas similares, pero sí de las
bases que les permitieron nacer: el transformador. Incluso menciona cosas no tan
famosas, como la computación neuromórfica, de la que no dudo que pueda
tener relevancia en el futuro, o impactar en nuevas tecnologías y nuevas formas
de crear inteligencia artificial.

Por su extensión, además, es un libro que vale la pena. Es cierto que se podría
mejorar un poco en la forma de escribirlo, pero no es algo que te vaya a impedir
extraer la información relevante.

Si tienes bases de matemáticas de nivel preparatoria, en la que entiendes el
álgebra y un poco de cálculo, estás del otro lado para entender este libro.
Si no, puedes saltarte los capítulos matemáticos y leer todo lo demás para
para darte una idea superficial del tema de Deep Learning y cómo puedes
empezar a aprender la parte más técnica e incluirlo en tus desarrollos.

Eso sí, este libro no tiene ni una línea de código, es un libro completamente
conceptual para entender la bases antes de aventarnos de cabeza a la programación.
